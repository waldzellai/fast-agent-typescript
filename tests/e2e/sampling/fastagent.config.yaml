default_model: passthrough

# Logging and Console Configuration:
logger:
  level: "error"
  type: "console"
  # path: "/path/to/logfile.jsonl"

  # Switch the progress display on or off
  progress_display: true

  # Show chat User/Assistant messages on the console
  show_chat: true
  # Show tool calls on the console
  show_tools: true
  # Truncate long tool responses on the console
  truncate_tools: true

mcp:
  servers:
    sampling_resource_anthropic:
      command: "uv"
      args: ["run", "sampling_resource_server.py"]
      sampling:
        model: "haiku"
    sampling_resource_openai:
      command: "uv"
      args: ["run", "sampling_resource_server.py"]
      sampling:
        model: "gpt-4.1-mini"

      # command: "bash"
      # args: ["-c", "uv run sampling_resource_server.py | tee sampling_output.log"]
      # sampling:
      #   model: "haiku"
